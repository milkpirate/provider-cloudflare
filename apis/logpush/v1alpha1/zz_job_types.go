// SPDX-FileCopyrightText: 2023 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type JobInitParameters struct {

	// (String) The kind of the dataset to use with the logpush job. Available values: access_requests, casb_findings, firewall_events, http_requests, spectrum_events, nel_reports, audit_logs, gateway_dns, gateway_http, gateway_network, dns_logs, network_analytics_logs, workers_trace_events, device_posture_results, zero_trust_network_sessions, magic_ids_detections, page_shield_events.
	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`, `magic_ids_detections`, `page_shield_events`.
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// (String) Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See Logpush destination documentation.
	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// (Boolean) Whether to enable the job.
	// Whether to enable the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (String) Use filters to select the events to include and/or remove from your logs. For more information, refer to Filters.
	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// (String) A higher frequency will result in logs being pushed on faster with smaller files. low frequency will push logs less often with larger files. Available values: high, low. Defaults to high.
	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// logs, "".
	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// (String) Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See Logpush options documentation.
	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// (Number) The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// (Number) The maximum interval in seconds for log batches. Value must be between 30 and 300.
	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// (Number) The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// (String) The name of the logpush job to create.
	// The name of the logpush job to create.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored. (see below for nested schema)
	// Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored.
	OutputOptions []OutputOptionsInitParameters `json:"outputOptions,omitempty" tf:"output_options,omitempty"`

	// (String) Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See Developer documentation.
	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`
}

type JobObservation struct {

	// (String) The account identifier to target for the resource. Must provide only one of account_id, zone_id.
	// The account identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// (String) The kind of the dataset to use with the logpush job. Available values: access_requests, casb_findings, firewall_events, http_requests, spectrum_events, nel_reports, audit_logs, gateway_dns, gateway_http, gateway_network, dns_logs, network_analytics_logs, workers_trace_events, device_posture_results, zero_trust_network_sessions, magic_ids_detections, page_shield_events.
	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`, `magic_ids_detections`, `page_shield_events`.
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// (String) Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See Logpush destination documentation.
	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// (Boolean) Whether to enable the job.
	// Whether to enable the job.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (String) Use filters to select the events to include and/or remove from your logs. For more information, refer to Filters.
	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// (String) A higher frequency will result in logs being pushed on faster with smaller files. low frequency will push logs less often with larger files. Available values: high, low. Defaults to high.
	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// logs, "".
	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// (String) Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See Logpush options documentation.
	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// (Number) The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// (Number) The maximum interval in seconds for log batches. Value must be between 30 and 300.
	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// (Number) The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// (String) The name of the logpush job to create.
	// The name of the logpush job to create.
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored. (see below for nested schema)
	// Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored.
	OutputOptions []OutputOptionsObservation `json:"outputOptions,omitempty" tf:"output_options,omitempty"`

	// (String) Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See Developer documentation.
	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`

	// (String) The zone identifier to target for the resource. Must provide only one of account_id, zone_id.
	// The zone identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`
}

type JobParameters struct {

	// (String) The account identifier to target for the resource. Must provide only one of account_id, zone_id.
	// The account identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	// +crossplane:generate:reference:type=github.com/milkpirate/provider-cloudflare/apis/account/v1alpha1.Account
	// +kubebuilder:validation:Optional
	AccountID *string `json:"accountId,omitempty" tf:"account_id,omitempty"`

	// Reference to a Account in account to populate accountId.
	// +kubebuilder:validation:Optional
	AccountIDRef *v1.Reference `json:"accountIdRef,omitempty" tf:"-"`

	// Selector for a Account in account to populate accountId.
	// +kubebuilder:validation:Optional
	AccountIDSelector *v1.Selector `json:"accountIdSelector,omitempty" tf:"-"`

	// (String) The kind of the dataset to use with the logpush job. Available values: access_requests, casb_findings, firewall_events, http_requests, spectrum_events, nel_reports, audit_logs, gateway_dns, gateway_http, gateway_network, dns_logs, network_analytics_logs, workers_trace_events, device_posture_results, zero_trust_network_sessions, magic_ids_detections, page_shield_events.
	// The kind of the dataset to use with the logpush job. Available values: `access_requests`, `casb_findings`, `firewall_events`, `http_requests`, `spectrum_events`, `nel_reports`, `audit_logs`, `gateway_dns`, `gateway_http`, `gateway_network`, `dns_logs`, `network_analytics_logs`, `workers_trace_events`, `device_posture_results`, `zero_trust_network_sessions`, `magic_ids_detections`, `page_shield_events`.
	// +kubebuilder:validation:Optional
	Dataset *string `json:"dataset,omitempty" tf:"dataset,omitempty"`

	// (String) Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See Logpush destination documentation.
	// Uniquely identifies a resource (such as an s3 bucket) where data will be pushed. Additional configuration parameters supported by the destination may be included. See [Logpush destination documentation](https://developers.cloudflare.com/logs/reference/logpush-api-configuration#destination).
	// +kubebuilder:validation:Optional
	DestinationConf *string `json:"destinationConf,omitempty" tf:"destination_conf,omitempty"`

	// (Boolean) Whether to enable the job.
	// Whether to enable the job.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`

	// (String) Use filters to select the events to include and/or remove from your logs. For more information, refer to Filters.
	// Use filters to select the events to include and/or remove from your logs. For more information, refer to [Filters](https://developers.cloudflare.com/logs/reference/logpush-api-configuration/filters/).
	// +kubebuilder:validation:Optional
	Filter *string `json:"filter,omitempty" tf:"filter,omitempty"`

	// (String) A higher frequency will result in logs being pushed on faster with smaller files. low frequency will push logs less often with larger files. Available values: high, low. Defaults to high.
	// A higher frequency will result in logs being pushed on faster with smaller files. `low` frequency will push logs less often with larger files. Available values: `high`, `low`. Defaults to `high`.
	// +kubebuilder:validation:Optional
	Frequency *string `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// logs, "".
	// The kind of logpush job to create. Available values: `edge`, `instant-logs`, `""`.
	// +kubebuilder:validation:Optional
	Kind *string `json:"kind,omitempty" tf:"kind,omitempty"`

	// (String) Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See Logpush options documentation.
	// Configuration string for the Logshare API. It specifies things like requested fields and timestamp formats. See [Logpush options documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#options).
	// +kubebuilder:validation:Optional
	LogpullOptions *string `json:"logpullOptions,omitempty" tf:"logpull_options,omitempty"`

	// (Number) The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	// The maximum uncompressed file size of a batch of logs. Value must be between 5MB and 1GB.
	// +kubebuilder:validation:Optional
	MaxUploadBytes *float64 `json:"maxUploadBytes,omitempty" tf:"max_upload_bytes,omitempty"`

	// (Number) The maximum interval in seconds for log batches. Value must be between 30 and 300.
	// The maximum interval in seconds for log batches. Value must be between 30 and 300.
	// +kubebuilder:validation:Optional
	MaxUploadIntervalSeconds *float64 `json:"maxUploadIntervalSeconds,omitempty" tf:"max_upload_interval_seconds,omitempty"`

	// (Number) The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	// The maximum number of log lines per batch. Value must be between 1000 and 1,000,000.
	// +kubebuilder:validation:Optional
	MaxUploadRecords *float64 `json:"maxUploadRecords,omitempty" tf:"max_upload_records,omitempty"`

	// (String) The name of the logpush job to create.
	// The name of the logpush job to create.
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored. (see below for nested schema)
	// Structured replacement for logpull_options. When including this field, the logpull_option field will be ignored.
	// +kubebuilder:validation:Optional
	OutputOptions []OutputOptionsParameters `json:"outputOptions,omitempty" tf:"output_options,omitempty"`

	// (String) Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See Developer documentation.
	// Ownership challenge token to prove destination ownership, required when destination is Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic. See [Developer documentation](https://developers.cloudflare.com/logs/logpush/logpush-configuration-api/understanding-logpush-api/#usage).
	// +kubebuilder:validation:Optional
	OwnershipChallenge *string `json:"ownershipChallenge,omitempty" tf:"ownership_challenge,omitempty"`

	// (String) The zone identifier to target for the resource. Must provide only one of account_id, zone_id.
	// The zone identifier to target for the resource. Must provide only one of `account_id`, `zone_id`.
	// +crossplane:generate:reference:type=github.com/milkpirate/provider-cloudflare/apis/zone/v1alpha1.Zone
	// +kubebuilder:validation:Optional
	ZoneID *string `json:"zoneId,omitempty" tf:"zone_id,omitempty"`

	// Reference to a Zone in zone to populate zoneId.
	// +kubebuilder:validation:Optional
	ZoneIDRef *v1.Reference `json:"zoneIdRef,omitempty" tf:"-"`

	// Selector for a Zone in zone to populate zoneId.
	// +kubebuilder:validation:Optional
	ZoneIDSelector *v1.Selector `json:"zoneIdSelector,omitempty" tf:"-"`
}

type OutputOptionsInitParameters struct {

	// (String) String to be prepended before each batch.
	// String to be prepended before each batch.
	BatchPrefix *string `json:"batchPrefix,omitempty" tf:"batch_prefix,omitempty"`

	// (String) String to be appended after each batch.
	// String to be appended after each batch.
	BatchSuffix *string `json:"batchSuffix,omitempty" tf:"batch_suffix,omitempty"`

	// 2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to false.
	// Mitigation for CVE-2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to `false`.
	Cve20214428 *bool `json:"cve20214428,omitempty" tf:"cve20214428,omitempty"`

	// (String) String to join fields. This field be ignored when record_template is set. Defaults to ,.
	// String to join fields. This field be ignored when record_template is set. Defaults to `,`.
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// (List of String) List of field names to be included in the Logpush output.
	// List of field names to be included in the Logpush output.
	FieldNames []*string `json:"fieldNames,omitempty" tf:"field_names,omitempty"`

	// (String) Specifies the output type. Available values: ndjson, csv. Defaults to ndjson.
	// Specifies the output type. Available values: `ndjson`, `csv`. Defaults to `ndjson`.
	OutputType *string `json:"outputType,omitempty" tf:"output_type,omitempty"`

	// between the records as separator.
	// String to be inserted in-between the records as separator.
	RecordDelimiter *string `json:"recordDelimiter,omitempty" tf:"record_delimiter,omitempty"`

	// (String) String to be prepended before each record. Defaults to {.
	// String to be prepended before each record. Defaults to `{`.
	RecordPrefix *string `json:"recordPrefix,omitempty" tf:"record_prefix,omitempty"`

	// (String) String to be appended after each record. Defaults to }.
	// String to be appended after each record. Defaults to `}`.
	RecordSuffix *string `json:"recordSuffix,omitempty" tf:"record_suffix,omitempty"`

	// separated list.
	// String to use as template for each record instead of the default comma-separated list.
	RecordTemplate *string `json:"recordTemplate,omitempty" tf:"record_template,omitempty"`

	// (Number) Specifies the sampling rate. Defaults to 1.
	// Specifies the sampling rate. Defaults to `1`.
	SampleRate *float64 `json:"sampleRate,omitempty" tf:"sample_rate,omitempty"`

	// (String) Specifies the format for timestamps. Available values: unixnano, unix, rfc3339. Defaults to unixnano.
	// Specifies the format for timestamps. Available values: `unixnano`, `unix`, `rfc3339`. Defaults to `unixnano`.
	TimestampFormat *string `json:"timestampFormat,omitempty" tf:"timestamp_format,omitempty"`
}

type OutputOptionsObservation struct {

	// (String) String to be prepended before each batch.
	// String to be prepended before each batch.
	BatchPrefix *string `json:"batchPrefix,omitempty" tf:"batch_prefix,omitempty"`

	// (String) String to be appended after each batch.
	// String to be appended after each batch.
	BatchSuffix *string `json:"batchSuffix,omitempty" tf:"batch_suffix,omitempty"`

	// 2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to false.
	// Mitigation for CVE-2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to `false`.
	Cve20214428 *bool `json:"cve20214428,omitempty" tf:"cve20214428,omitempty"`

	// (String) String to join fields. This field be ignored when record_template is set. Defaults to ,.
	// String to join fields. This field be ignored when record_template is set. Defaults to `,`.
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// (List of String) List of field names to be included in the Logpush output.
	// List of field names to be included in the Logpush output.
	FieldNames []*string `json:"fieldNames,omitempty" tf:"field_names,omitempty"`

	// (String) Specifies the output type. Available values: ndjson, csv. Defaults to ndjson.
	// Specifies the output type. Available values: `ndjson`, `csv`. Defaults to `ndjson`.
	OutputType *string `json:"outputType,omitempty" tf:"output_type,omitempty"`

	// between the records as separator.
	// String to be inserted in-between the records as separator.
	RecordDelimiter *string `json:"recordDelimiter,omitempty" tf:"record_delimiter,omitempty"`

	// (String) String to be prepended before each record. Defaults to {.
	// String to be prepended before each record. Defaults to `{`.
	RecordPrefix *string `json:"recordPrefix,omitempty" tf:"record_prefix,omitempty"`

	// (String) String to be appended after each record. Defaults to }.
	// String to be appended after each record. Defaults to `}`.
	RecordSuffix *string `json:"recordSuffix,omitempty" tf:"record_suffix,omitempty"`

	// separated list.
	// String to use as template for each record instead of the default comma-separated list.
	RecordTemplate *string `json:"recordTemplate,omitempty" tf:"record_template,omitempty"`

	// (Number) Specifies the sampling rate. Defaults to 1.
	// Specifies the sampling rate. Defaults to `1`.
	SampleRate *float64 `json:"sampleRate,omitempty" tf:"sample_rate,omitempty"`

	// (String) Specifies the format for timestamps. Available values: unixnano, unix, rfc3339. Defaults to unixnano.
	// Specifies the format for timestamps. Available values: `unixnano`, `unix`, `rfc3339`. Defaults to `unixnano`.
	TimestampFormat *string `json:"timestampFormat,omitempty" tf:"timestamp_format,omitempty"`
}

type OutputOptionsParameters struct {

	// (String) String to be prepended before each batch.
	// String to be prepended before each batch.
	// +kubebuilder:validation:Optional
	BatchPrefix *string `json:"batchPrefix,omitempty" tf:"batch_prefix,omitempty"`

	// (String) String to be appended after each batch.
	// String to be appended after each batch.
	// +kubebuilder:validation:Optional
	BatchSuffix *string `json:"batchSuffix,omitempty" tf:"batch_suffix,omitempty"`

	// 2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to false.
	// Mitigation for CVE-2021-44228. If set to true, will cause all occurrences of ${ in the generated files to be replaced with x{. Defaults to `false`.
	// +kubebuilder:validation:Optional
	Cve20214428 *bool `json:"cve20214428,omitempty" tf:"cve20214428,omitempty"`

	// (String) String to join fields. This field be ignored when record_template is set. Defaults to ,.
	// String to join fields. This field be ignored when record_template is set. Defaults to `,`.
	// +kubebuilder:validation:Optional
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// (List of String) List of field names to be included in the Logpush output.
	// List of field names to be included in the Logpush output.
	// +kubebuilder:validation:Optional
	FieldNames []*string `json:"fieldNames,omitempty" tf:"field_names,omitempty"`

	// (String) Specifies the output type. Available values: ndjson, csv. Defaults to ndjson.
	// Specifies the output type. Available values: `ndjson`, `csv`. Defaults to `ndjson`.
	// +kubebuilder:validation:Optional
	OutputType *string `json:"outputType,omitempty" tf:"output_type,omitempty"`

	// between the records as separator.
	// String to be inserted in-between the records as separator.
	// +kubebuilder:validation:Optional
	RecordDelimiter *string `json:"recordDelimiter,omitempty" tf:"record_delimiter,omitempty"`

	// (String) String to be prepended before each record. Defaults to {.
	// String to be prepended before each record. Defaults to `{`.
	// +kubebuilder:validation:Optional
	RecordPrefix *string `json:"recordPrefix,omitempty" tf:"record_prefix,omitempty"`

	// (String) String to be appended after each record. Defaults to }.
	// String to be appended after each record. Defaults to `}`.
	// +kubebuilder:validation:Optional
	RecordSuffix *string `json:"recordSuffix,omitempty" tf:"record_suffix,omitempty"`

	// separated list.
	// String to use as template for each record instead of the default comma-separated list.
	// +kubebuilder:validation:Optional
	RecordTemplate *string `json:"recordTemplate,omitempty" tf:"record_template,omitempty"`

	// (Number) Specifies the sampling rate. Defaults to 1.
	// Specifies the sampling rate. Defaults to `1`.
	// +kubebuilder:validation:Optional
	SampleRate *float64 `json:"sampleRate,omitempty" tf:"sample_rate,omitempty"`

	// (String) Specifies the format for timestamps. Available values: unixnano, unix, rfc3339. Defaults to unixnano.
	// Specifies the format for timestamps. Available values: `unixnano`, `unix`, `rfc3339`. Defaults to `unixnano`.
	// +kubebuilder:validation:Optional
	TimestampFormat *string `json:"timestampFormat,omitempty" tf:"timestamp_format,omitempty"`
}

// JobSpec defines the desired state of Job
type JobSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     JobParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider JobInitParameters `json:"initProvider,omitempty"`
}

// JobStatus defines the observed state of Job.
type JobStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        JobObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true

// Job is the Schema for the Jobs API. Provides a resource which manages Cloudflare Logpush jobs. For Logpush jobs pushing to Amazon S3, Google Cloud Storage, Microsoft Azure or Sumo Logic, this resource cannot be automatically created. In order to have this automated, you must have: cloudflare_logpush_ownership_challenge: Configured to generate the challenge to confirm ownership of the destination.cloudflare_logpush_job: Create and manage the Logpush Job itself.
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,cloudflare}
type Job struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.dataset) || (has(self.initProvider) && has(self.initProvider.dataset))",message="spec.forProvider.dataset is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.destinationConf) || (has(self.initProvider) && has(self.initProvider.destinationConf))",message="spec.forProvider.destinationConf is a required parameter"
	Spec   JobSpec   `json:"spec"`
	Status JobStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// JobList contains a list of Jobs
type JobList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Job `json:"items"`
}

// Repository type metadata.
var (
	Job_Kind             = "Job"
	Job_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Job_Kind}.String()
	Job_KindAPIVersion   = Job_Kind + "." + CRDGroupVersion.String()
	Job_GroupVersionKind = CRDGroupVersion.WithKind(Job_Kind)
)

func init() {
	SchemeBuilder.Register(&Job{}, &JobList{})
}
